{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b6a4c6-284b-4542-86c0-fd97f6e2f1c1",
   "metadata": {},
   "source": [
    "# Pre-Processing Agent\n",
    "\n",
    "- This notebook helps you generate needed prompts for the LLM. \n",
    "- You still need access to an LLM and execute the code provided by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74c4d96e-bb9b-46de-97fd-3b87ce7a6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "def gather_summary(df):\n",
    "    # 2. Capture df.info() output\n",
    "    buffer = io.StringIO()\n",
    "    df.info(buf=buffer)\n",
    "    info_text = buffer.getvalue()\n",
    "    print(info_text)\n",
    "\n",
    "    # 3. Calculate missing value stats\n",
    "    missing_stats = (df.isna().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "    missing_summary = \"\\n\".join([f\"{col}: {val:.2f}%\" for col, val in missing_stats.items()])\n",
    "    print(missing_summary)\n",
    "\n",
    "    # 4. Get column data types\n",
    "    column_types = \"\\n\".join([f\"{col}: {dtype}\" for col, dtype in df.dtypes.items()])\n",
    "    print(column_types)\n",
    "\n",
    "    # 5. Get unique value counts\n",
    "    unique_counts = df.nunique()  # Will no longer fail on unhashable dict\n",
    "    unique_counts_summary = \"\\n\".join([f\"{col}: {count}\" for col, count in unique_counts.items()])\n",
    "    print(unique_counts_summary)\n",
    "\n",
    "    summary_text = f\"\"\"\n",
    "    Dataset Name: {dataset_name}\n",
    "    ----------------------------\n",
    "    Shape: {df.shape[0]} rows x {df.shape[1]} columns\n",
    "    \n",
    "    Column Data Types:\n",
    "    {column_types}\n",
    "    \n",
    "    Missing Value Percentage:\n",
    "    {missing_summary}\n",
    "    \n",
    "    Unique Value Counts:\n",
    "    {unique_counts_summary}\n",
    "    \n",
    "    Data (first {n_sample} rows):\n",
    "    {df.head(n_sample).to_string()}\n",
    "    \n",
    "    Data Description:\n",
    "    {df.describe().to_string()}\n",
    "    \n",
    "    Data Info:\n",
    "    {info_text}\n",
    "    \"\"\"\n",
    "    print(summary_text)\n",
    "\n",
    "    return summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f756131-fdc4-49e5-a324-8f3fec0c7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ADD YOUR DATASET.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b27a05c-0a8b-4414-b50f-8ee93072d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample=30\n",
    "summary_text = \"\"\n",
    "if os.path.exists(dataset_name):\n",
    "    df = pd.read_csv(dataset_name)\n",
    "    df = df.convert_dtypes()\n",
    "    summary_text = gather_summary(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97147207-7724-4b5a-81b2-52ef13774042",
   "metadata": {},
   "source": [
    "# Data Cleaning Expert Agent\t\n",
    "\n",
    "- Collects dataset characteristics from your dataset\n",
    "- Prompts LLM for which steps to perform based on the data characteristics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb00a4bc-0f76-4681-a8c1-74a139b5120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if summary_text:    \n",
    "    prompt=f\"\"\"\n",
    "    You are a Data Cleaning Expert. Given the following information about the data, \n",
    "    recommend a series of numbered steps to take to clean and preprocess it. \n",
    "    The steps should be tailored to the data characteristics and should be helpful \n",
    "    for a data cleaning agent that will be implemented.\n",
    "    \n",
    "    General Steps:\n",
    "    Things that should be considered in the data cleaning steps:\n",
    "    \n",
    "    * Removing columns if more than 40 percent of the data is missing\n",
    "    * Imputing missing values with the mean of the column if the column is numeric\n",
    "    * Imputing missing values with the mode of the column if the column is categorical\n",
    "    * Converting columns to the correct data type\n",
    "    * Removing duplicate rows\n",
    "    * Removing rows with missing values\n",
    "    * Removing rows with extreme outliers (3X the interquartile range)\n",
    "    \n",
    "    Custom Steps:\n",
    "    * Analyze the data to determine if any additional data cleaning steps are needed.\n",
    "    * Recommend steps that are specific to the data provided. Include why these steps are necessary or beneficial.\n",
    "    * If no additional steps are needed, simply state that no additional steps are required.\n",
    "    \n",
    "    IMPORTANT:\n",
    "    Make sure to take into account any additional user instructions that may add, remove or modify some of these steps. Include comments in your code to explain your reasoning for each step. Include comments if something is not done because a user requested. Include comments if something is done because a user requested.\n",
    "    \n",
    "    Below are summaries of all datasets provided:\n",
    "    {summary_text}\n",
    "    \n",
    "    Return steps as a numbered list. You can return short code snippets to demonstrate actions. But do not return a fully coded solution. The code will be generated separately by a Coding Agent.\n",
    "    \n",
    "    Avoid these:\n",
    "    1. Do not include steps to save files.\n",
    "    2. Do not include unrelated user instructions that are not related to the data cleaning.\n",
    "    \"\"\"\n",
    "\n",
    "    print(prompt)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191dffd7-083c-4fec-8ff4-9e57ffb40cdc",
   "metadata": {},
   "source": [
    "## Now, you must prompt an LLM \n",
    "\n",
    "- Ask for which steps to perform based on the data characteristics\n",
    "- Then, manually extract suggested steps and add them to the following list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67c3088c-303f-40d5-a8ed-315344a89738",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_steps = [\n",
    "    # TODO: Add recommended steps here:    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79fb361b-cc5a-44c1-8596-b025a4aaf714",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_name = \"clean_data\"\n",
    "\n",
    "if summary_text and len(recommended_steps) > 0:\n",
    "    steps_text = \"\\n\".join(map(str, recommended_steps))\n",
    "    \n",
    "    prompt2=f\"\"\"You are a Data Cleaning Agent. Your job is to create a {function_name}() function that can be run on the data \n",
    "    provided using the following recommended steps.\n",
    "    \n",
    "    Recommended Steps:\n",
    "    {steps_text}\n",
    "    \n",
    "    You can use Pandas, Numpy, and Scikit Learn libraries to clean the data.\n",
    "    \n",
    "    Below are summaries of all datasets provided. Use this information about the data to help determine how to \n",
    "    clean the data:\n",
    "    \n",
    "    {summary_text}\n",
    "    \n",
    "    Return Python code in ```python``` format with a single function definition, {function_name}(data_raw), that \n",
    "    includes all imports inside the function.\n",
    "    \n",
    "    Return code to provide the data cleaning function:\n",
    "    \n",
    "    def {function_name}(data_raw):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        ...\n",
    "        return data_cleaned\n",
    "    \n",
    "    Best Practices and Error Preventions:\n",
    "    \n",
    "    Always ensure that when assigning the output of fit_transform() from SimpleImputer to a Pandas DataFrame \n",
    "    column, you call .ravel() or flatten the array, because fit_transform() returns a 2D array while a DataFrame column is 1D\n",
    "    \"\"\"\n",
    "        \n",
    "    print(prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb9809-b83f-4328-8518-330ab53cc443",
   "metadata": {},
   "source": [
    "## Fix Code Agent\n",
    "\n",
    "In case of an error, provide stack-trace to LLM and re-run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3cf7746-353f-4e81-8a63-b7b31870eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_snippet = \"\"\"\"\"\"\n",
    "error = \"\"\"\"\"\"\n",
    "\n",
    "if code_snippet and error:\n",
    "    data_cleaner_prompt = f\"\"\"\n",
    "            You are a Fix Code Agent. Your job is to create a {function_name}() function that can be run on the data provided. \n",
    "            The function is currently broken and needs to be fixed.\n",
    "            \n",
    "            Make sure to only return the function definition for {function_name}().\n",
    "            \n",
    "            Return Python code in ```python``` format with a single function definition, {function_name}(data_raw), \n",
    "            that includes all imports inside the function.\n",
    "            \n",
    "            This is the broken code (please fix): \n",
    "            {code_snippet}\n",
    "    \n",
    "            Last Known Error:\n",
    "            {error}\n",
    "            \"\"\"\n",
    "    print(data_cleaner_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645de5d-ad84-4372-9450-d75be987a0b7",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "# Submit 6-fold via Moodle:\n",
    "- The executed notebook \n",
    "- A html export of the executed notebook\n",
    "- Original and cleaned CSV file\n",
    "- **Summary Statistics before and after cleaning!**\n",
    "\n",
    "### You must hand in this exercise via moodle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce0d5ce-bd14-4c2e-b3da-f0d7d0fdd5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
